{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split, cross_validate\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.ensemble import AdaBoostClassifier, BaggingClassifier, RandomForestClassifier, VotingClassifier\n",
    "from sklearn.metrics import confusion_matrix, precision_recall_curve, roc_curve, accuracy_score\n",
    "from sklearn.pipeline import FeatureUnion, Pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import numpy as np\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.mixture import GaussianMixture\n",
    "import pandas as pd\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, PolynomialFeatures\n",
    "from sklearn.manifold import LocallyLinearEmbedding, Isomap, TSNE\n",
    "from sklearn.pipeline import FeatureUnion, Pipeline\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression, Perceptron\n",
    "from sklearn.svm import LinearSVC, NuSVC, LinearSVR, NuSVR, SVC\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import AdaBoostClassifier, BaggingClassifier, RandomForestClassifier, VotingClassifier\n",
    "from sklearn.metrics import confusion_matrix, precision_recall_curve, roc_curve\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, PolynomialFeatures\n",
    "from sklearn.manifold import LocallyLinearEmbedding, Isomap, TSNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Leemos el CSV de entrenamiento\n",
    "file_path = \"../traintabs/\"\n",
    "file_name = \"traintab07.csv\"\n",
    "X_init = pd.read_csv(file_path+file_name, sep = ',', decimal = '.', index_col=0)\n",
    "\n",
    "#Leemos el CSV de entrenamiento\n",
    "file_path = \"../traintabs/\"\n",
    "file_name = \"train_label.csv\"\n",
    "Y_train_init = pd.read_csv(file_path+file_name, sep = ',', decimal = '.', index_col=0)\n",
    "\n",
    "\n",
    "#Quitamos la columna de´nombre de la foto que no nos da ninguna info\n",
    "X_train_init = X_init.iloc[:, 1:]\n",
    "#Y_train_init.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogTransformer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self # return get_feat_area(X)\n",
    "\n",
    "    def transform(self, X):\n",
    "        \n",
    "        def get_log(features):\n",
    "            numeric_columns = features.select_dtypes(include=[np.number]).columns\n",
    "            log_df = pd.DataFrame()\n",
    "            \n",
    "            for col in numeric_columns:\n",
    "                positive_values = features[col][features[col] > 0]  # Filtra solo los valores positivos de la columna\n",
    "                log_df[f\"log_{col}\"] = np.log1p(positive_values)\n",
    "\n",
    "            return log_df\n",
    "        \n",
    "        return get_log(X)\n",
    "\n",
    "class CorrTransformer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self # return get_feat_area(X)\n",
    "\n",
    "    def transform(self, X):\n",
    "        \n",
    "        def get_cor(X_f):\n",
    "            mat_R = X_f.corr()\n",
    "            R_th = .97\n",
    "\n",
    "            aux = np.abs( np.triu(mat_R.values) - np.eye(X_f.shape[1]) )\n",
    "            ind_row = np.argmax(aux, axis=0)\n",
    "            ind_col=0\n",
    "            aboveTh_list=[]\n",
    "            removed_list=[]\n",
    "            for ir in ind_row:\n",
    "                if (aux[ir,ind_col] >= R_th):\n",
    "                    aboveTh_list.append((ir,ind_col))\n",
    "                    removed_list.append(ind_col)\n",
    "                ind_col=ind_col+1\n",
    "            drop_list = [aux for aux in X.columns[removed_list] ]\n",
    "            X_f = X_f.drop(columns=drop_list)\n",
    "            X_f.head()\n",
    "        return get_cor(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PIPELINE\n",
    "\n",
    "\n",
    "more_features = []\n",
    "\n",
    "poly_degree = 2\n",
    "polyfeat = PolynomialFeatures(poly_degree).set_output(transform=\"pandas\")\n",
    "more_features.append( ('addPolyFeat', polyfeat) )\n",
    "\n",
    "#extractor = LogTransformer()\n",
    "#more_features.append( ('log_transformer', extractor) )\n",
    "pipe1 = Pipeline(more_features)\n",
    "\n",
    "lastprocess = []  #--------------\n",
    "\n",
    "#Normalizado\n",
    "scaler2 = MinMaxScaler().set_output(transform='pandas')\n",
    "lastprocess.append( ('scaler2', scaler2) )\n",
    "\n",
    "\n",
    "##########\n",
    "# Isomap #\n",
    "##########\n",
    "\n",
    "'''n_components = 8\n",
    "n_neighbors = 15\n",
    "metric = 'l1' #<-- 'cityblock', 'cosine', 'euclidean' , 'haversine' , 'l1' , 'l2' , 'manhattan' , 'nan_euclidean' \n",
    "max_iter = 150\n",
    "\n",
    "isom = Isomap(n_neighbors=n_neighbors, n_components=n_components, metric=metric,\n",
    "              max_iter=max_iter)\n",
    "\n",
    "lastprocess.append( ('isom', isom) )'''\n",
    "#Filtrado por corr\n",
    "#cor_selector = CorrTransformer()\n",
    "#lastprocess.append( ('corr_selector', cor_selector) )\n",
    "\n",
    "pipe2 = Pipeline(lastprocess)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Modelo\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "\n",
    "n_estimators = 50\n",
    "learning_rate= .1\n",
    "choice_clf = 'linearSVC' #<-- 'linearSVC', 'SVC', 'NBC' , 'DT'\n",
    "#-LinearSVC is slower other linear clfs. but it allows SAMME.R algorithm\n",
    "\n",
    "lin_clf  = SVC(kernel='linear', C=1, probability=True)\n",
    "svc_clf  = SVC(kernel='rbf', degree=3 ,C=1, probability=True)\n",
    "tree_clf = DecisionTreeClassifier(max_depth=1)\n",
    "nbc_clf  = GaussianNB()\n",
    "\n",
    "if choice_clf == 'linearSVC':\n",
    "    ada_clf = AdaBoostClassifier(lin_clf,\n",
    "                     n_estimators=n_estimators, algorithm=\"SAMME.R\", learning_rate=learning_rate)    \n",
    "if choice_clf == 'SVC':\n",
    "    ada_clf = AdaBoostClassifier(svc_clf,\n",
    "                     n_estimators=n_estimators, algorithm=\"SAMME.R\", learning_rate=learning_rate)\n",
    "elif choice_clf == 'DT':\n",
    "    ada_clf = AdaBoostClassifier(tree_clf,\n",
    "                     n_estimators=n_estimators, algorithm=\"SAMME.R\", learning_rate=learning_rate)\n",
    "elif choice_clf == 'NBC':\n",
    "    ada_clf = AdaBoostClassifier(nbc_clf,\n",
    "                     n_estimators=n_estimators, algorithm=\"SAMME.R\", learning_rate=learning_rate)\n",
    "\n",
    "#pipeRF = Pipeline([('random', RandomForestClassifier())])\n",
    "\n",
    "\n",
    "'''n_components=5\n",
    "covariance_type='full' \n",
    "max_iter=15\n",
    "random_state=1234\n",
    "\n",
    "pipeRF = Pipeline([('clf_GMM', GaussianMixture(n_components=n_components, \n",
    "                                                covariance_type=covariance_type, max_iter=max_iter, random_state=random_state))])\n",
    "'''\n",
    "'''\n",
    "hidden_layer_sizes=[32,16,8,4]\n",
    "activation='tanh'        #<- ‘identity’, ‘logistic’, ‘tanh’, ‘relu’\n",
    "learning_rate='adaptive' #<- 'constant’, ‘invscaling’, ‘adaptive’\n",
    "learning_rate_init=0.001\n",
    "max_iter=1000\n",
    "\n",
    "pipeRF = Pipeline([('clf_NN', MLPClassifier(hidden_layer_sizes=hidden_layer_sizes,\n",
    "                      activation=activation, learning_rate=learning_rate,\n",
    "                      learning_rate_init=learning_rate_init, max_iter=max_iter))])\n",
    "'''\n",
    "'''\n",
    "max_depth = 1\n",
    "n_estimators = 100\n",
    "learning_rate= 1\n",
    "\n",
    "pipeRF = GradientBoostingClassifier(max_depth=max_depth,        \\\n",
    "                                    n_estimators=n_estimators,  \\\n",
    "                                    learning_rate=learning_rate)\n",
    "'''\n",
    "'''from sklearn.neighbors import KNeighborsClassifier\n",
    "pipeRF = KNeighborsClassifier(n_neighbors=4)'''\n",
    "'''n_estimators = 100\n",
    "max_leaf_nodes = 16\n",
    "max_depth = 1\n",
    "\n",
    "pipeRF = RandomForestClassifier(n_estimators=n_estimators,\n",
    "                                max_depth=max_depth)\n",
    "                                #max_leaf_nodes=max_leaf_nodes)\n",
    "'''\n",
    "voting_system = 'soft' #<-- choices are 'soft' , 'hard'\n",
    "\n",
    "lin_clf  = LogisticRegression()\n",
    "svm_clf  = SVC(kernel='rbf', degree=3, C=2, probability=True)\n",
    "tree_clf = DecisionTreeClassifier(max_depth=9)\n",
    "nbc_clf  = GaussianNB()\n",
    "\n",
    "pipeRF = VotingClassifier(\n",
    "    estimators=[('lin', lin_clf),  ('svc', svm_clf), ('tree', tree_clf), ('nbc',nbc_clf)],\n",
    "    voting=voting_system)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-5 {color: black;}#sk-container-id-5 pre{padding: 0;}#sk-container-id-5 div.sk-toggleable {background-color: white;}#sk-container-id-5 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-5 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-5 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-5 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-5 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-5 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-5 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-5 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-5 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-5 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-5 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-5 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-5 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-5 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-5 div.sk-item {position: relative;z-index: 1;}#sk-container-id-5 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-5 div.sk-item::before, #sk-container-id-5 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-5 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-5 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-5 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-5 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-5 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-5 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-5 div.sk-label-container {text-align: center;}#sk-container-id-5 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-5 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-5\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;pipe1&#x27;,\n",
       "                 Pipeline(steps=[(&#x27;addPolyFeat&#x27;, PolynomialFeatures())])),\n",
       "                (&#x27;pipe2&#x27;, Pipeline(steps=[(&#x27;scaler2&#x27;, MinMaxScaler())])),\n",
       "                (&#x27;pipeRF&#x27;, RandomForestClassifier(max_depth=1))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-27\" type=\"checkbox\" ><label for=\"sk-estimator-id-27\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;pipe1&#x27;,\n",
       "                 Pipeline(steps=[(&#x27;addPolyFeat&#x27;, PolynomialFeatures())])),\n",
       "                (&#x27;pipe2&#x27;, Pipeline(steps=[(&#x27;scaler2&#x27;, MinMaxScaler())])),\n",
       "                (&#x27;pipeRF&#x27;, RandomForestClassifier(max_depth=1))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-28\" type=\"checkbox\" ><label for=\"sk-estimator-id-28\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">pipe1: Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;addPolyFeat&#x27;, PolynomialFeatures())])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-29\" type=\"checkbox\" ><label for=\"sk-estimator-id-29\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">PolynomialFeatures</label><div class=\"sk-toggleable__content\"><pre>PolynomialFeatures()</pre></div></div></div></div></div><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-30\" type=\"checkbox\" ><label for=\"sk-estimator-id-30\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">pipe2: Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;scaler2&#x27;, MinMaxScaler())])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-31\" type=\"checkbox\" ><label for=\"sk-estimator-id-31\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MinMaxScaler</label><div class=\"sk-toggleable__content\"><pre>MinMaxScaler()</pre></div></div></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-32\" type=\"checkbox\" ><label for=\"sk-estimator-id-32\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(max_depth=1)</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('pipe1',\n",
       "                 Pipeline(steps=[('addPolyFeat', PolynomialFeatures())])),\n",
       "                ('pipe2', Pipeline(steps=[('scaler2', MinMaxScaler())])),\n",
       "                ('pipeRF', RandomForestClassifier(max_depth=1))])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe = Pipeline([('pipe1',pipe1),('pipe2',pipe2),('pipeRF',pipeRF) ])\n",
    "pipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/juanmontes/.local/lib/python3.10/site-packages/sklearn/base.py:1152: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix:\n",
      "       0    1\n",
      "0  1121  104\n",
      "1   942  101\n",
      "Accuracy: 0.5388007054673721\n"
     ]
    }
   ],
   "source": [
    "# Calcular el índice del 80% de las filas\n",
    "percentage = 0.2\n",
    "split_index = int(len(X_train_init) * percentage)\n",
    "\n",
    "# Tomar el 80% inicial de las filas como nuevo X_train\n",
    "X_train = X_train_init[:split_index]\n",
    "Y_train = Y_train_init[:split_index]\n",
    "\n",
    "\n",
    "# Tomar el 20% restante de las filas como nuevo X_test\n",
    "X_test = X_train_init[split_index:]\n",
    "Y_test = Y_train_init[split_index:]\n",
    "\n",
    "\n",
    "pipe.fit(X_train, Y_train)\n",
    "y_hat= pipe.predict(X_test)\n",
    "\n",
    "print('Confusion matrix:\\n',pd.DataFrame(confusion_matrix(Y_test, y_hat)))\n",
    "accuracy = accuracy_score(Y_test, y_hat)\n",
    "print('Accuracy:', accuracy)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
